{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def average_precision_at_k(theta, labels, k, dist_fn):\n",
    "    dist = dist_fn(theta)\n",
    "    np.fill_diagonal(dist, np.inf)\n",
    "    idx = np.argpartition(dist, k - 1)[:k, :]\n",
    "    return np.mean(labels[idx] == labels[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "def hellinger(theta):\n",
    "    return euclidean_distances(np.sqrt(theta))\n",
    "\n",
    "def dot(theta):\n",
    "    return 1 - np.dot(theta, theta.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from numba import jit, prange, autojit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True, parallel = True)\n",
    "def outer(X, fn):\n",
    "    dist = np.empty((X.shape[0], X.shape[0]), dtype = np.float32)\n",
    "    for i in prange(X.shape[0]):\n",
    "        for j in prange(i):\n",
    "            dist[j,i] = dist[i,j] = fn(X[i,:], X[j,:])           \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def _dot(x,y):\n",
    "    return np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def kl(p, q):\n",
    "    return np.dot(p, np.log(q / p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def sym_kl(p, q):\n",
    "    return kl(p, q) + kl(q, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def js(p, q):\n",
    "    m = (p + q) / 2\n",
    "    return kl(p, m) / 2 + kl(q, m) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def overlap(p, q):\n",
    "    return 1 - np.sum(np.minimum(p,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def l1_norm(p, q):\n",
    "    return np.sum(np.abs(p - q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def bc(p, q):\n",
    "    return -np.log(np.sum(np.sqrt(p * q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dist_fns = {'cosine' : cosine_distances,\n",
    "            'eucl' : euclidean_distances,\n",
    "            'hellinger' : hellinger,\n",
    "            'dot' : dot,\n",
    "            'sym_kl' : lambda x: outer(x, sym_kl),\n",
    "            'js' : lambda x: outer(x, js),\n",
    "            'overlap': lambda x: outer(x, overlap),\n",
    "            'l1' : lambda x: outer(x, l1_norm),\n",
    "            'bc' : lambda x: outer(x, bc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def eval_topic_model(corpus, model, labels, k = 100, dist_fns = dist_fns):\n",
    "    theta = model.get_document_topics(corpus, minimum_probability = 0)\n",
    "    theta = matutils.corpus2dense(theta, num_docs=len(corpus), num_terms=model.num_topics, dtype = np.float32)\n",
    "    theta = np.asarray(theta, dtype = np.float32)\n",
    "    theta = theta.transpose()\n",
    "    best_score = 0\n",
    "    best_dist = None\n",
    "    for (dist, f) in dist_fns.items():\n",
    "        score = average_precision_at_k(theta, labels, k, f)\n",
    "        if score > best_score:\n",
    "            best_score, best_dist = score, dist\n",
    "    return best_score, best_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cats = ['rec.autos', 'rec.motorcycles',\n",
    "        'sci.crypt', 'sci.electronics', \n",
    "        'sci.med', 'sci.space',\n",
    "        'talk.politics.guns', 'talk.religion.misc',\n",
    "        'rec.sport.baseball', 'rec.sport.hockey']\n",
    "newsgroups = fetch_20newsgroups(subset = 'all', categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "model = spacy.load('en', disable = ['parser','ner'])\n",
    "\n",
    "def tokenize(string):\n",
    "    email_pattern = re.compile(r'[^@]+@[^@]+\\.[^@]+', re.IGNORECASE & re.UNICODE)\n",
    "    header_pattern = re.compile(\n",
    "        r'^summary:|^x-newsreader:.*|^date:.*'\n",
    "        r'|^disclaimer:.*|^distribution:.*|^organization:.*'\n",
    "        r'|^nntp-posting-host:.*|^keywords:.*|^to:.*'\n",
    "        r'|^in-reply-to:.*|^x-news-reader:.*|^lines:.*',\n",
    "        re.IGNORECASE & re.UNICODE)\n",
    "    special_char_pattern = re.compile(r\"[^\\w']|_\")\n",
    "    number_pattern = re.compile(r'\\b\\d+\\b')\n",
    "    writes_pattern = re.compile(r'^.*writes:$')\n",
    "    \n",
    "    string = header_pattern.sub(' ', string)\n",
    "    string = email_pattern.sub(' ', string)\n",
    "    string = number_pattern.sub(' ', string)\n",
    "    string = writes_pattern.sub(' ', string)\n",
    "    string = special_char_pattern.sub(' ', string)\n",
    "    \n",
    "    string = ' '.join([w for w in string.split() if len(w) > 2])\n",
    "    \n",
    "    return [w.lemma_ for w in model(string) if w.pos_ not in {'SPACE','PUNCT'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from gensim import matutils\n",
    "\n",
    "en_stop = get_stop_words('en')\n",
    "en_stop += ['would', 'subject', 're', 'don', 'jan','feb', 'mar', 'apr', 'may', 'june','july', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "texts = []\n",
    "for i in newsgroups['data']:\n",
    "    \n",
    "    raw = i.lower()\n",
    "    tokens = tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    texts.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 topics AP@100 = 0.576 (sym_kl distance)\n",
      "10 topics AP@100 = 0.698 (js distance)\n",
      "15 topics AP@100 = 0.657 (js distance)\n",
      "20 topics AP@100 = 0.632 (sym_kl distance)\n",
      "25 topics AP@100 = 0.614 (js distance)\n",
      "30 topics AP@100 = 0.569 (sym_kl distance)\n",
      "35 topics AP@100 = 0.655 (js distance)\n",
      "40 topics AP@100 = 0.615 (js distance)\n",
      "45 topics AP@100 = 0.599 (sym_kl distance)\n",
      "50 topics AP@100 = 0.592 (sym_kl distance)\n",
      "55 topics AP@100 = 0.625 (sym_kl distance)\n",
      "60 topics AP@100 = 0.626 (sym_kl distance)\n"
     ]
    }
   ],
   "source": [
    "from gensim import matutils\n",
    "for num_topics in range(5, 61,5):\n",
    "    model = gensim.models.ldamodel.LdaModel(corpus, num_topics=num_topics, id2word = dictionary, passes=20)\n",
    "    score, dist = eval_topic_model(corpus, model, labels)\n",
    "    print(\"%2i topics AP@100 = %.3f (%s distance)\" % (num_topics, score, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020*\"space\" + 0.016*\"nasa\" + 0.012*\"never\" + 0.011*\"gov\" + 0.010*\"com\" + 0.009*\"orbit\" + 0.007*\"satellit\" + 0.007*\"mission\" + 0.007*\"-pron-\" + 0.006*\"earth\"\n",
      "0.021*\"edu\" + 0.019*\"com\" + 0.011*\"-pron-\" + 0.011*\"harvard\" + 0.009*\"ibm\" + 0.007*\"disclaim\" + 0.007*\"spdcc\" + 0.007*\"time\" + 0.007*\"berkeley\" + 0.006*\"ramsey\"\n",
      "0.018*\"edu\" + 0.016*\"com\" + 0.011*\"chip\" + 0.011*\"new\" + 0.010*\"phone\" + 0.009*\"ripem\" + 0.009*\"net\" + 0.008*\"line\" + 0.008*\"appl\" + 0.008*\"use\"\n",
      "0.082*\"-pron-\" + 0.009*\"can\" + 0.009*\"will\" + 0.008*\"one\" + 0.007*\"peopl\" + 0.007*\"write\" + 0.006*\"use\" + 0.006*\"say\" + 0.006*\"know\" + 0.006*\"get\"\n",
      "0.057*\"-pron-\" + 0.009*\"get\" + 0.008*\"can\" + 0.008*\"will\" + 0.008*\"edu\" + 0.008*\"good\" + 0.007*\"'s\" + 0.007*\"one\" + 0.006*\"year\" + 0.006*\"just\"\n",
      "0.098*\"com\" + 0.017*\"uunet\" + 0.013*\"netcom\" + 0.011*\"univers\" + 0.011*\"dod\" + 0.010*\"pat\" + 0.010*\"uucp\" + 0.009*\"seattl\" + 0.008*\"edu\" + 0.008*\"wisdom\"\n",
      "0.105*\"edu\" + 0.012*\"gatech\" + 0.010*\"prism\" + 0.008*\"uc\" + 0.006*\"mil\" + 0.006*\"cray\" + 0.006*\"washington\" + 0.006*\"caltech\" + 0.006*\"ohio\" + 0.005*\"state\"\n",
      "0.013*\"radio\" + 0.012*\"edu\" + 0.011*\"univers\" + 0.011*\"georgia\" + 0.008*\"amateur\" + 0.008*\"phone\" + 0.007*\"pilot\" + 0.006*\"hamburg\" + 0.006*\"pt\" + 0.006*\"uni\"\n",
      "0.048*\"key\" + 0.015*\"public\" + 0.013*\"encrypt\" + 0.011*\"messag\" + 0.010*\"use\" + 0.010*\"secur\" + 0.009*\"de\" + 0.008*\"pgp\" + 0.008*\"can\" + 0.007*\"rsa\"\n",
      "0.058*\"edu\" + 0.019*\"uiuc\" + 0.019*\"-pron-\" + 0.007*\"cso\" + 0.007*\"bitnet\" + 0.006*\"iastat\" + 0.006*\"pitt\" + 0.006*\"ericsson\" + 0.006*\"cmu\" + 0.006*\"com\"\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=20)\n",
    "for i in range(model.num_topics):\n",
    "    print(model.print_topic(i, topn = 10))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
